# Distribución de Bernouli

El problema es encontrar la probabilidad de que en n ensayos con dos posibles resultados, cada uno de ellos con probabilidad p y 1-p  ocurran k con probabilidad p.

Supongamos que tenemos 3 ensayos.
n = 3
k = 0, 1, 2, 3

Es igual a $\begin{pmatrix} 3 \\ 2\end{pmatrix} = \frac{3!}{(3-2)!~2!} = 3$ 

Ahora con n = 4 y k = 2

Es igual a: $\begin{pmatrix}4 \\ 2 \end{pmatrix} = \frac{4!}{(4-2)!~2!} = 6$

Como es un producto podemos verlos como: $P(x=k)= \begin{pmatrix}n \\ k\end{pmatrix}p^{k}(1-p)^{u-k}$ 
Para calcular la media tenemos que recordar el binomio de Newton: $(a+b)^{n} = \sum\limits_{k=0}^{n}\begin{pmatrix}n \\ k\end{pmatrix} a^{u-k}b^{k}$ 

Problema: Calcula el promedio de una variable aleatoria de Bernulli con parametros $(n,p)$.

$$\mu_{x}= E[x] = \sum\limits_{k}k~P[x=k] = \sum\limits_{k=0}^{n} k~\begin{pmatrix}n \\ k\end{pmatrix}p^{k}(1-p)^{n-k} = \sum\limits k\frac{n!}{k!(n-k)!} p^{k}(1-p)^{n-k}$$
$$= P_{n}\sum\limits_{k=1}^{n}\frac{(n-1)!}{[(n-1)-(k-1)]!~(k-1)!}p^{{(k-1)}} (1-p) ^{([n-1]-[k-1])}$$

Se hace un cambio de variable $\ell = k-1$ cuando $n=1 ~~~\ell=0$
$$M_{x}=Pn\sum\limits_{n}\frac{(n-1)!}{([n-1]-\ell)*\ell}p^{\ell}(1-p)^{[(n-1)-\ell]}$$

Donde $\sum\limits_{n}\frac{(n-1)!}{([n-1]-\ell)*\ell}$ es igual a $\begin{pmatrix}n-1 \\ \ell\end{pmatrix}$ y tenemos que:
$$pn\sum\limits_{\ell=0}^{n-1} \begin{pmatrix}n-1 \\ \ell\end{pmatrix}p^{\ell}(1-p)^{(n-1)-\ell}=pn((1-p)+p)^{n-1}=pn$$


##### Ejercicio.
Calcular la varianza de una variable discreta de bernulli

# Variable continua

La variable aleatoria continua puede tomar un valor del intervalo de los reales, lo que podemos calcular es que la variable caiga en un intervalo diferencial, $P(x\leq X\leq x+dx) = f_{x}(x)dx = dF(x)$ la ultima función se llama funcion de distribución o función de distribución acumulada.

$$dF(x) = f_{x}(x)dx = \frac{dF(x)}{dx} = f_{x}(x)$$

$$P(a\leq X \leq) = \int_{a}^{b}dF(x) = \int_{a}^{b}f_{x}(x)dx$$ 
por tanto se puede calcular la probabilidad de $P(X\leq x) =\int_{-\infty}^{x}f_{x}(t)dt$ 
El evento seguro sería cuando la variable sea menor a infinito $P(X\leq\infty) = 1 =\int_{-\infty}^{\infty}f_{x}(x) dx$ 

###### Función distribución uniforme 
Entre cero y uno
Para: 
$$0\leq U\leq1 con~f_{u}(x)=\left\lbrace\begin{matrix} 1&0\leq X\leq 1 \\ 0&caso~contrario\end{matrix}\right.$$

$$\mu_{x}= \int_{-\infty}^{\infty}x~f_{x}(x)~dx$$ 
$$V_{x}=\int_{-\infty}^{\infty}(u-\mu_{x})^{2}f_{x}(x)~dx$$ 

Proposición. Sea $U$ una variable aleatoria y $f_{v}$ y $F_{v}$ una función de densidad de probabilidad y de distribución respectivamente. Entonces la variable aleatoria $V=F^{-1}(u)$ se distribuye como $f_{v}$ 

Lo que sees que: $P(u\leq x) =x$ para la función distribución uniforme
$$P(u\leq x) = \int_{0}^{x}1dt = [t]_{0}^{x}= x-0 = x$$
Pero $P(V\leq x)$ se puede escribir como:
Al querer evaluar V en cualquier valor lo podemos ver como:
$$P(V\leq x) = P(F^{1}(U)\leq X)$$
Como los de abajo son momentos podemos verlo de la siguiente forma
$$F^{1}(U)) \leq X\iff U\leq F(X)$$
Verlo así:
$$P(V\leq x) = P(F^{1}(U)\leq X) = P(u\leq F(x))=F(x)$$
queda como:
$$P(v\leq x)=F(X)=\int_{-\infty}^{x}f_{x}(t)dt$$

###### Ejercicio:
Integral
$$f_{x}=\lambda e^{-\lambda x}$$
calcular la integral y graficar el histograma